{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Model on Embeddings (Extracted Features)\n",
    "In this feature-based approach, we are using the embeddings from the previous transformation step to train some models on a multilabel classification task.\n",
    "These results will be considered the baseline for more advanced modelling techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score,classification_report\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_embedding_name=\"llama3.2.1b\"#\"all-mpnet-base-v2-finetuned\"#\"llama3.2.1b\"#\"all-mpnet-base-v2-finetuned\"#\"ModernBERT-base\"#\"all-mpnet-base-v2\"#\"bert-base-uncased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings</th>\n",
       "      <th>Alert User</th>\n",
       "      <th>Ambient Atmosphere</th>\n",
       "      <th>Ambient Luminance</th>\n",
       "      <th>Ambient Temperature</th>\n",
       "      <th>Control Hub</th>\n",
       "      <th>Energy Saving</th>\n",
       "      <th>Gardening</th>\n",
       "      <th>Other</th>\n",
       "      <th>Other Appliances</th>\n",
       "      <th>Outlet Control</th>\n",
       "      <th>Robot Control</th>\n",
       "      <th>Security</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[5.8760797e-06  0.018332329  0.032247532  -0.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.01548752  0.007120902  0.032546464  -0.005...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.007748441  0.0021770685  0.036084786  -0.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.0013106825  0.00499818  0.053116668  -0.00...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.013440807  -0.019121878  0.019484065  -0.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>[0.0040453877  0.028940763  0.03343941  0.0087...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>[-0.015449206  0.001333692  0.006457404  -0.02...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>[-0.01638672  -0.0019023608  0.05313262  -0.01...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>[-0.018889135  0.01379838  0.0349957  0.007016...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>[-0.016756753  -0.023842216  0.05784838  -0.00...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             embeddings  Alert User  \\\n",
       "0     [5.8760797e-06  0.018332329  0.032247532  -0.0...           0   \n",
       "1     [-0.01548752  0.007120902  0.032546464  -0.005...           0   \n",
       "2     [-0.007748441  0.0021770685  0.036084786  -0.0...           0   \n",
       "3     [-0.0013106825  0.00499818  0.053116668  -0.00...           0   \n",
       "4     [-0.013440807  -0.019121878  0.019484065  -0.0...           1   \n",
       "...                                                 ...         ...   \n",
       "2555  [0.0040453877  0.028940763  0.03343941  0.0087...           0   \n",
       "2556  [-0.015449206  0.001333692  0.006457404  -0.02...           1   \n",
       "2557  [-0.01638672  -0.0019023608  0.05313262  -0.01...           0   \n",
       "2558  [-0.018889135  0.01379838  0.0349957  0.007016...           0   \n",
       "2559  [-0.016756753  -0.023842216  0.05784838  -0.00...           0   \n",
       "\n",
       "      Ambient Atmosphere  Ambient Luminance  Ambient Temperature  Control Hub  \\\n",
       "0                      0                  1                    0            0   \n",
       "1                      0                  1                    0            0   \n",
       "2                      0                  1                    0            0   \n",
       "3                      0                  0                    0            1   \n",
       "4                      0                  0                    0            0   \n",
       "...                  ...                ...                  ...          ...   \n",
       "2555                   0                  1                    0            0   \n",
       "2556                   0                  0                    0            0   \n",
       "2557                   0                  0                    0            0   \n",
       "2558                   1                  0                    0            0   \n",
       "2559                   0                  0                    0            0   \n",
       "\n",
       "      Energy Saving  Gardening  Other  Other Appliances  Outlet Control  \\\n",
       "0                 0          0      0                 0               0   \n",
       "1                 0          0      0                 0               0   \n",
       "2                 0          0      0                 0               0   \n",
       "3                 0          0      0                 0               0   \n",
       "4                 0          0      0                 0               0   \n",
       "...             ...        ...    ...               ...             ...   \n",
       "2555              0          0      0                 0               0   \n",
       "2556              0          0      0                 0               0   \n",
       "2557              0          0      1                 0               0   \n",
       "2558              0          0      0                 0               0   \n",
       "2559              0          0      1                 0               0   \n",
       "\n",
       "      Robot Control  Security  \n",
       "0                 0         0  \n",
       "1                 0         0  \n",
       "2                 0         0  \n",
       "3                 0         0  \n",
       "4                 0         0  \n",
       "...             ...       ...  \n",
       "2555              0         0  \n",
       "2556              0         0  \n",
       "2557              0         0  \n",
       "2558              0         0  \n",
       "2559              0         0  \n",
       "\n",
       "[2560 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(\"out/3_elaborated_dataset_for_multilabel_training_\"+model_embedding_name+\"_.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alert User',\n",
       " 'Ambient Atmosphere',\n",
       " 'Ambient Luminance',\n",
       " 'Ambient Temperature',\n",
       " 'Control Hub',\n",
       " 'Energy Saving',\n",
       " 'Gardening',\n",
       " 'Other',\n",
       " 'Other Appliances',\n",
       " 'Outlet Control',\n",
       " 'Robot Control',\n",
       " 'Security']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=[col for col in df.columns if col != \"embeddings\"]\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[5.8760797e-06  0.018332329  0.032247532  -0.0110866055  0.0056896866  -0.038031887  -0.0052733608  0.010633435  0.004938283  0.0030828542  0.024305897  -0.00034804727  0.010212543  -0.009306585  -0.02243945  0.0034766113  0.0013601297  -0.006926455  -0.007860296  -0.02537369  -0.019756323  -0.018142285  0.020376485  0.000500108  -0.0052967947  -0.006420259  0.0315943  -0.034798063  0.023545695  -0.004330015  -0.012828634  0.015793506  -0.005533178  -0.0027263244  0.0046459553  -0.031276304  -0.011349223  0.008606491  -0.008529677  0.0026761044  -0.00177175  -0.016179532  -0.0016162902  -0.0059591294  -0.012968814  0.027853627  0.010361526  0.013106162  -0.014220956  0.0051352116  0.012267384  0.0026726997  0.014480509  0.013825935  -0.0067624403  -0.008854733  0.010245699  -0.020308683  0.0030219995  0.025489  0.02453635  0.022993717  4.29167e-05  -0.0074858237  0.064596586  -0.020746429  0.009347191  0.00039841706  -0.009177946  -0.0007617805  0.0075129936  -0.01062468  0.025060652  0.014227167  0.047197923  -0.004892368  -0.013798036  -0.008578373  -0.006793951  0.019241247  -0.018658327  -0.0037266496  -0.0056486493  -0.010145718  -0.022623252  0.01928221  0.014908813  0.0064761895  -0.0010639308  0.00040355217  0.024384543  -0.03834942  -0.009728343  0.004579612  -0.01812488  0.024698978  0.002536835  -0.0057299477  -0.0012067311  0.01465567  0.0017726973  0.018317515  -0.008766739  0.003162112  0.001635213  -0.008254388  0.01906572  -0.014354949  -0.0024499544  -0.022004135  0.007459449  0.0036774823  0.004711518  -0.02106056  0.0019807557  -0.01625028  0.032816097  -0.002198093  -0.008050786  0.0035452433  -0.0040580253  -0.027518589  0.0035933724  -0.035304066  -0.011795234  0.017259523  0.0012211748  0.03253981  0.01165783  -0.0138169415  -0.0028308593  -0.008968186  0.0036883038  0.007907428  -0.008841867  0.000834502  -0.00083371636  -0.008762608  0.0018484629  -0.003934947  -0.015540335  -0.0018623171  0.023903402  0.021682624  -0.011518204  -0.0133229485  0.00042871243  0.0027356313  -0.013507161  0.00811324  0.011371667  -0.023732895  0.016288767  0.029904226  -0.027799323  0.021610143  0.012475203  -0.027233562  0.008672133  0.009079308  0.01038342  0.031903446  0.0133545995  -0.0072355387  0.004912627  0.015661575  -0.0060480954  0.004085799  -0.005961003  0.00019283364  0.004500737  0.0030744947  -0.01752806  0.0109811565  -0.00713344  0.013981973  0.0042194077  0.009527128  0.008281524  -0.008563065  0.0016118705  -0.01639284  -0.004092618  -0.0146163795  0.005030518  0.0047000563  0.00016163201  0.0050284485  -0.001415538  0.0058561517  0.018344963  -0.01897124  -0.06386017  -0.00857384  0.014675444  -0.032344393  0.0047627995  0.047351785  0.010663662  0.008139019  0.0018244573  -0.011253414  0.017191373  -0.0064651724  -0.0024577533  -0.0050929408  0.006385863  -0.005192315  0.00971098  -0.030395394  0.007954579  -0.0037843247  -0.0028744997  -0.005402979  0.005324209  -0.009296335  -0.010753439  -0.0008820771  -0.00903881  -0.005407521  0.0028038933  0.0161785  -0.011287896  -0.02135502  -0.049100664  0.010387583  -0.020948749  -0.0022993651  0.0014943354  -0.011588366  0.028177088  0.0016261721  -0.00034293297  0.0011103312  -0.039294127  -0.015672661  0.0046833064  0.009225803  -0.014164631  -0.016054858  -0.023813028  -0.014742371  0.0021383434  0.032038588  0.0063470425  0.015888898  0.003366781  -0.0029816953  0.0023566524  0.0029834379  -0.02014489  0.006660944  0.01657587  0.022517197  -0.013260018  0.0024371324  -0.0135909375  -0.011931614  0.0029813743  0.016389972  0.008490788  0.012658503  -0.00650208  -0.0075453003  0.011936107  -0.0033438285  0.011825286  0.00222614  -0.030056285  -0.0023639593  -0.008690635  0.007234857  0.0128474  0.02735249  0.024141781  0.010688286  -0.007684045  0.0009308416  -0.03798394  0.014972717  0.007084969  -0.016983442  -0.017993968  0.012893652  -0.016827347  0.0024977918  0.011421059  0.015012615  0.01675651  0.0047560823  -0.0072445385  0.003382782  -0.0012324798  -0.028051648  0.004357447  -0.01965181  -0.025635641  0.014201476  -0.0060043945  -0.0066161193  -0.0051650065  -0.014386047  0.007841459  0.0028743015  -0.006010041  -0.0014113314  0.006289049  -0.037234593  0.011517203  -0.002367293  0.021925073  -0.0131627545  0.0067221844  -0.012254295  -0.0074253017  0.006966838  -0.0033260663  -0.01117047  -0.013841261  0.0259668  0.0030429715  -0.023604121  -0.00041136757  0.023507668  0.009934475  -0.007143705  0.013639062  0.008342376  0.008197004  0.015713885  0.0072517153  -0.018900955  0.023809407  -0.008856772  -0.010422803  0.014261919  -0.0011635706  -0.00717089  -0.0052544526  0.015371803  -0.00025142115  -0.016689755  -0.00012508505  0.018537113  7.629998e-05  -0.003024235  -0.027118735  0.0057932893  -0.0018719215  0.003701463  0.013048005  -0.039419208  -0.0010450347  -0.018392619  -0.03222175  -0.014230764  -0.013908661  0.009400774  -0.013816534  -0.0012921097  -0.020800252  -0.007649377  0.008502713  0.0071518784  0.028978862  -0.021252574  -0.010505894  0.007527366  -0.019424526  -0.0007550541  0.08555073  0.017498806  0.0150524415  -0.003057265  0.0013704981  0.0056002946  0.02297666  -0.022241415  -0.027784547  -0.01574365  -0.0036665685  0.0020658849  0.013238885  -0.005261576  -0.0028518203  0.00071831385  -0.017341346  -0.011560097  -0.0023452619  0.004806582  0.04743005  0.0018658825  -0.0042207143  -0.013569922  0.013229574  -0.016380081  0.011239899  -0.0019161062  -0.012862142  0.029948711  -0.0042726803  0.018932268  0.003227699  0.005873326  -0.018449869  0.005979307  -0.0002962758  0.0030113591  -0.001445265  0.021399869  -0.0019241349  0.014765655  0.0024372996  -0.0017075448  0.0060909325  -0.0057709506  -0.0018127816  0.009829904  -0.011728405  0.017025458  0.011489354  0.0014840616  0.006331707  0.031632915  0.011319168  0.021696413  0.007898613  0.034025412  -0.0068992916  0.0062928298  -0.003300822  -0.025051797  0.011105842  0.0040709134  -0.0022060513  0.0066561373  0.007257364  0.010360183  -0.012495138  0.013911794  0.008543308  0.065860644  -0.009435471  0.019249035  -0.017059717  0.005365834  0.0047230283  0.0027738502  0.0057232385  0.0002738156  0.005807714  -0.011032445  0.012009489  -0.020172799  -0.012470545  0.018051654  -0.0116535425  -0.03449244  0.008453677  -0.043428026  0.004952836  -0.0012995154  0.030650506  0.0100801885  -0.015390635  -0.023246387  -0.011790262  -0.008104474  -0.013901154  -0.0059700087  -0.016738616  0.014118389  0.0139833735  0.014390046  -0.03301793  0.0104650585  0.008566082  -0.0039505023  0.0026976787  -0.014398731  0.010508661  0.022858575  -0.02341704  -0.0011437258  0.0075199986  -0.035320535  0.014483213  -0.020044567  -0.006224465  0.022562182  0.027882796  -0.013386725  0.0026829357  0.0007755466  -0.004459173  0.017657166  0.0065515228  0.030105973  -0.028238015  -0.0010773898  0.013940542  -0.017688325  0.0047956165  -0.0008249465  0.009169874  -0.0022743777  0.016583342  0.009702809  0.011245147  0.02420504  0.026325176  0.004070511  0.0095513975  -0.036048327  0.020339912  0.0010895656  0.03743444  -0.033915456  0.015901605  -0.035654474  0.006681121  -0.013807477  -0.079054356  -0.0013341815  0.029624034  -0.03869021  0.00030340275  0.010072368  -0.0065460014  0.017914357  -0.0059827254  -0.013497201  -0.034119844  -0.0037182602  -0.020112626  0.025560135  -0.032687344  -0.0038983296  -0.013451884  0.0074261646  -0.00970627  -0.00548699  0.027227938  0.0073353313  0.0025838295  -0.016197145  -0.0035667003  -0.03838981  0.024670754  -0.009236132  0.008873288  0.013984891  0.012905866  -0.0067257634  -0.0003191822  0.0064750845  0.015867984  -0.017817609  0.014643287  -0.004913831  0.0040748967  0.016097201  -0.0040830276  0.027380742  -0.026519937  -0.019243019  0.0057242066  0.009798689  -0.021883601  0.009129022  -0.0065901643  0.0225502  0.002883779  -0.002157207  0.007901428  -0.01308524  -0.018355437  -0.0008898454  -0.018318374  0.0057210666  0.019946074  0.0044983746  0.021528788  -0.0032729728  0.01749122  -0.025665477  -0.011640943  0.007873298  0.016611205  0.016588306  0.01988606  0.011060002  0.015179372  0.0015277113  -0.008394811  -0.000559285  -0.01890352  0.006723838  0.022409555  0.0031699908  -0.018839475  0.018135896  -0.008298092  0.018609697  -0.014601073  0.00664555  0.0065963296  -0.011732023  0.032378074  -0.022849519  -0.004680192  0.011335144  0.0013811439  -0.025089007  -0.012851789  0.024237782  0.0027129438  -0.011513345  0.014307672  0.01263108  -0.011012825  0.00073754805  0.012253347  0.006866813  -0.03393696  0.017240034  -0.009427553  0.014773415  -0.016798431  -0.009083091  -0.017902749  -0.011510653  0.004522453  -0.025410894  0.014420227  0.0015442619  -0.013618524  -0.028949767  -0.0038930392  -0.008728068  -0.005442606  -0.0026145503  -0.025263947  -0.005721423  0.035756152  -0.021707771  -0.026526762  0.029859195  0.016295286  -0.016653828  9.873208e-05  0.03974739  0.005895495  -0.013299606  -0.0016467643  -0.015686708  0.021880755  0.023782287  -0.03642773  -0.0029866  -0.023381313  0.03944243  0.0042515397  0.03763526  -0.013262776  0.0018594989  -0.0037953204  0.01237044  -0.008993062  -0.006599894  0.019117298  -0.003094533  -0.0050089257  0.00711227  -0.011512057  0.005682912  0.1554546  0.019993747  -0.0143728405  0.00106631  -0.00053646666  -0.004647383  -0.016547183  -0.00050761626  0.005416469  -0.0066936985  -0.020404506  0.0066613466  -0.036970917  -0.01345768  0.011323266  0.026603248  0.0074548447  0.003317609  0.012846355  0.010535991  -0.01647511  -0.01045876  0.012243441  0.0027031982  0.004838226  -0.0056122635  0.028994357  -0.019517722  -0.00087546743  -0.013578192  -0.015151852  -0.0060629365  0.0050101364  -0.003774445  -0.003811378  -0.008529933  0.008260106  0.0011792209  0.009233632  -0.004537485  0.0049679982  -0.016930534  0.008068191  0.012052624  0.007999172  0.018506946  -0.012723676  -0.004121896  -0.011544835  0.008894858  -0.022296263  0.017720245  0.0056566154  -0.012038111  -0.0042586722  0.024764216  -0.034816094  -0.021399545  -0.028680177  0.0006058945  -0.021881793  0.037479453  0.0069826017  -0.0070571443  0.018166494  0.012592962  -0.012229712  -0.029111352  0.032165036  -0.036091145  0.0065783565  0.009156222  0.013522809  -0.01559501  -0.0031241404  -0.019311348  -0.019302897  -0.020957276  0.002780994  -0.01209024  -0.027564334  0.014102484  -0.014060979  -0.03284235  -0.005967943  -0.000145046  0.020394515  0.009719247  0.044199146  -0.02915839  0.017822377  -0.008271596  -0.0049738837  0.013794127  -0.011203706  0.019296682  -0.012476232  0.003454661  -0.010164119  -0.022070508  -0.017804286  -0.0362799  0.021595312  -0.016975017  -0.0020645452  -0.020538611  -0.025675016  -0.015626933  -4.972658e-06  -0.03508067  0.0140549205  0.017811837  0.008049927  -0.0087147765  0.0064736335  -0.036847398  -0.002959621  0.008582814  -0.005831719  -0.00888373  -0.014630793  0.007948893  0.012151014  0.026622599  0.005838316  -0.01516852  -0.0020742996  0.0085587995  -0.012691053  -0.032275856  -0.0076397127  -0.0041974457  -0.016811196  0.025809642  0.008767898  -0.015858134  0.003547401  0.0067467163  0.0035042556  -0.029764123  -0.027782004  0.030685058  -0.026004132  0.031245355  0.0076809996  0.0137206735  -0.024784153  -0.030635372  -0.009911744  0.014554186  0.004726698  0.0137818325  0.019767517  0.006713391  0.003443722  -0.009712748  0.0034352478  -0.010339609  -0.02651154  0.0016245173  0.004724341  -0.013478386  0.007057819  -0.06108889  -0.0047738054  -0.0025553165  -0.012397011  0.012250744  0.012776422  0.007729079  0.0071486793  0.016820757  -0.027192896  -0.0028270467  0.0060357247  0.012470759  -0.027157074  0.030799914  0.017917722  0.021321738  -0.003922478  0.0021346032  -0.00402581  -0.010260799  -0.014888385  -0.006519953  0.004634188  0.021925518  0.005022222  -0.0044585452  -0.017545545  -0.00085460575  -0.011909083  0.046285514  -0.018909877  0.0013093726  0.0066622575  -0.019326378  -0.009091771  -0.03347608  0.022234442  0.0010658426  0.013867429  0.022959817  -0.0073855016  -0.07839006  0.012869524  0.0015299399  -0.006820304  0.006631044  0.042460296  -0.011625682  -0.011113268  0.011676633  -0.0019136089  0.015710905  -0.011748051  -0.020680383  0.0051505594  -0.007756115  0.04962127  -0.0047744117  0.012497324  0.0052794814  0.005445683  0.019363659  0.014078721  -0.010918215  -0.014713753  0.00087527174  -0.01141262  -0.026753591  0.0042067347  -4.0429535e-05  -0.0032559356  0.008586123  0.0058308323  0.032835778  0.008570647  -0.0023907796  0.0012182451  -0.01762737  -0.0053798645  -0.032578304  0.004996165  -0.002154561  -0.017849818  0.0055653728  -0.0014997703  -0.0070521417  -0.013407823  -0.017343221  0.025709148  0.03808176  -0.013384746  0.060128696  0.009358825  0.004693996  0.018684156  -0.035429906  -0.032474995  -0.0021987478  -0.04803251  -0.0056852507  -0.0038948182  -0.0007003435  0.017805818  0.019262942  0.034409925  0.007810438  0.003037345  0.013129103  0.027339354  -0.001210403  0.0012297777  0.0074488134  -0.014521306  0.00033851498  -0.018794995  -0.020542398  0.04146269  -0.007849754  0.007129013  -0.003524292  -0.0035079187  0.012731512  0.0010137673  0.005391132  0.01670005  -0.005557697  -0.015679939  0.0051811384  -0.0037988045  0.016261457  0.018831763  0.011916045  -0.00949649  -0.002943757  -0.007898835  0.026739253  -0.00517945  -0.006661439  0.01907611  -0.015073581  0.030326758  0.0012051848  0.011322771  -0.013612559  0.025611049  0.0017902568  0.016189331  -0.0006275509  -0.018965943  0.0072631724  0.010903237  -0.015938427  0.01421765  0.01864359  -0.025478736  -0.0036048286  0.015332335  0.0070166565  0.016977541  0.009468856  -0.036576837  -0.0038253851  -0.024323368  -0.016628934  0.006443095  0.023220684  0.0018391584  -0.0065005003  0.02397445  -0.00036504466  -0.0048431284  -0.00083684037  -0.014808945  0.007247226  0.0025532946  -0.012153944  -0.006286086  -0.003869847  -0.010857926  0.0080293985  0.010918865  -0.016050136  0.011593521  0.03007286  -0.0038559611  -0.0013333386  0.001407955  -0.022367034  0.0092289  -0.0006899443  -0.006175255  -0.011145904  0.018187815  -0.0018802042  -0.004949688  0.014569161  -0.0047563855  -0.018427312  0.004236732  -0.001365625  -0.0068544033  0.011723247  0.015020473  0.0005392999  -0.03197703  0.011741614  0.00411177  0.0077256854  0.038067713  0.012049735  -0.009312563  -0.0067923223  0.013810296  -0.010540578  0.0110420715  0.005795638  -0.010214022  -0.026089573  -0.0045692557  -0.005127673  -0.015330983  -0.00451045  0.0073061166  -0.010621515  -0.0008446768  0.016798742  -0.015566698  -0.010296414  -0.014460191  0.0012237949  -0.007987921  -0.0051079323  0.0072380174  0.0064296913  0.0045980485  0.04005138  -0.04205028  0.012570305  -0.015485219  0.002246744  -0.017984364  -0.01911592  -0.0034039358  0.018861042  -0.018408926  0.02968987  0.043645546  0.007045935  0.0012563509  -0.0042530173  -0.04287385  -0.009586963  -0.0029325602  0.020414904  -0.0084732445  0.010393621  0.005335787  0.005928161  0.00024194058  0.011967496  -0.008350638  -0.030972965  0.0056236894  -0.032270074  -0.016867157  -0.026606811  -0.02257931  -0.004295838  0.0034506444  0.0032217272  0.004560814  0.031725638  0.024053251  0.031056564  0.0011580056  -0.010691638  -0.018347513  0.01954831  -0.026374701  0.010654603  0.0044026054  0.0011845572  0.02241836  0.012774979  -0.015351433  0.005721487  0.019263478  0.008761572  -0.0050122095  0.028827954  -0.0152260205  -0.0024530357  -0.019970465  -1.1677757e-05  -0.030758714  0.021165812  0.007688441  0.017099181  -0.0058342814  0.015721869  -0.039880138  0.023408975  -0.009839646  0.0047282907  0.02389579  -0.04717152  0.022616062  0.010907035  -0.031849038  -0.00334448  -0.015637327  -0.00894703  -0.012631653  -0.008079721  -0.016608141  0.0056886044  0.009233983  -0.012350168  0.0022312847  0.020897064  0.010644941  -0.011030033  0.00021216969  -0.012757088  0.027915088  0.012547964  0.05697548  -0.015274009  -0.0035793777  -0.006598971  -0.025193082  -0.010380172  0.00074597937  0.0077522444  0.012532872  -0.001864786  -0.02218765  -0.008951629  0.005982601  0.010566939  -0.014097317  -0.00027509822  0.0024742987  -0.00488807  -0.010562253  -0.0016850027  0.0146817975  0.019967256  -0.010238838  -0.0022162695  0.027863545  -0.0033054487  -0.0014753256  0.0074023153  -0.005275881  0.008796539  -0.02895595  0.00055136235  0.03128088  -0.010881318  0.014191249  -0.02736984  0.0035315976  -0.0005295168  0.0015606472  0.012952947  0.018309634  -0.036476713  -0.008706168  -0.014773069  0.019005477  0.018105185  -0.022500541  -0.0022670345  0.00026662712  0.00330547  -0.006071673  0.014409196  -0.016776882  0.023070231  0.03782605  0.0019261094  0.00029970417  0.050095983  -0.013311246  -0.0040994533  0.0065255417  -0.0024227244  0.0052501503  0.017466722  0.010014003  -0.016091619  -0.006337653  -0.022327216  -0.007948121  0.01398905  0.01867879  -0.033032402  0.019357627  -0.0115652485  -0.0036630272  -0.011913703  0.008919023  -0.020534173  -0.007296541  0.02540892  -0.022555243  0.02055016  -0.015712498  -0.016493347  -0.024505768  -0.0063609774  0.007573669  -0.0022580128  -0.0010531378  0.013908212  0.018144304  0.01597255  0.0046072993  0.0032742335  0.0073971553  0.011801835  -0.0049652006  -0.00018104407  0.025538713  0.008462093  -0.004366872  -0.011974949  0.022977645  0.011339613  0.03029753  0.0038847807  -0.00016710813  0.0045867823  -0.0075276885  -0.017042683  -0.003919758  -0.0046067876  0.009873719  0.011022771  -0.0002995806  -0.0026884696  -0.021725396  -0.011675428  0.00625476  0.009781485  -0.009204434  0.030473659  -0.002931574  -0.010185841  -0.0012812241  0.017384402  -0.00929153  0.029784024  -0.035920594  0.0024194424  0.0021454575  0.0031521867  0.0076155895  0.008540776  -0.008433513  -0.031067362  -0.01880018  0.010229199  0.010043386  0.024523232  -0.010738525  -0.04335913  0.04023611  -0.028344175  -0.017394245  0.007909789  0.0076767355  -0.000436145  0.021254804  -0.01014713  0.0034617833  -0.0041779657  -0.0024035308  0.028557379  -0.0030237576  -0.006821263  -0.013088442  0.024115402  -0.0014217289  -0.0032473719  0.008419596  0.007975568  -0.0080630295  -0.009782309  -0.009959672  0.010070636  0.02845934  0.025545627  -0.0062705986  0.00019869006  -0.0061458084  0.0028489854  -0.008647952  0.015634395  -0.00047857835  0.0024904597  0.024688466  0.001886957  0.0016870294  -0.009787016  0.022209503  0.040778156  0.0213576  0.0011786628  -0.00049604283  0.01437796  -0.0056020156  0.010079935  -0.027624836  -0.02785579  0.008582589  0.0064148605  -0.01890402  0.0072839037  -0.0047487402  0.0018268293  0.010852487  0.21527958  -0.0052814004  0.001288738  0.019390019  0.01876649  -0.0053346427  -0.08788499  -0.01125038  0.005395436  0.021491854  -0.0073061944  0.0061605372  -0.033798557  -0.0058962917  0.0045059198  -0.02073464  -0.028804125  -0.028333042  -0.010045345  -0.0051517533  0.0095693525  0.020760207  -0.01849904  -0.0014875556  0.005085737  0.011663927  -0.010942616  -0.0141506065  0.0042904816  -0.02671435  -0.012250748  0.03878355  0.006766509  -0.01394138  0.00932468  0.031169593  -0.0041016717  0.013671366  -0.002537482  -0.010971843  0.018852169  -0.01641922  -0.0035340725  -0.0061563402  -0.053780004  -0.005117464  -0.101532936  -0.0075359605  0.0003810607  0.011801732  0.009268882  -0.019384507  0.0018916413  -0.060324106  0.0024550005  0.010401408  -0.014555967  -0.008128248  0.02909098  0.010435279  -0.0047159065  0.0013531322  0.018278548  -0.01044486  0.0041120537  -0.008275964  0.007822466  -0.022916771  -0.03085261  0.008435994  0.02704868  0.0034252575  -0.0106992675  0.0010380703  -0.008608619  0.02196354  -0.03401212  0.036745  0.025168674  -0.024585385  -0.0596415  0.0004819232  -0.0005316238  0.0101601165  0.017480187  0.031333134  -0.026912794  -0.012002184  0.0027930678  0.03485098  0.017974364  -0.009911164  0.006233956  0.0003344706  0.05666798  0.017991342  -0.022574347  -0.0032976014  -0.0029471198  -0.0024627673  0.00033782594  -0.01738103  0.014195548  -0.0014556351  -0.018471692  -0.03391171  0.0051152017  0.012660879  0.01871862  0.019282442  0.012463385  0.010749917  0.007990992  -0.01357421  0.0061168876  0.00037132215  0.034825712  0.009090601  0.0136978235  0.028523764  0.009090263  0.013236036  0.0024853263  -0.022566045  -0.023079416  0.006208188  0.01420401  -0.008900798  -0.013375358  -0.0017510259  -0.015406237  -0.0036818476  0.0032070167  0.019064035  0.0033241832  -0.0047213463  0.02622229  -0.042659324  -0.010572516  -0.005347371  0.019345883  -0.002456493  -0.022974515  0.013207496  -0.027577179  0.0083812075  -0.00035544188  0.0049649123  0.007496134  -0.011536579  0.012357936  -0.005747106  -0.009340166  -0.008638973  0.02370217  0.008892508  -0.0028021685  -0.021532534  -0.008325593  0.025221601  -0.0018708804  -0.011542696  -0.0013317133  -0.045169406  -0.025349379  -0.008727517  -0.0025789244  0.008862764  -0.0006890942  0.00063276  -0.011998096  -0.005028937  -0.004776989  -0.03417835  -0.010123543  -0.0040908596  0.014679221  -0.001739506  0.010394821  -0.019910421  -0.0012997753  -0.009464161  -0.034782145  -0.03287321  -9.422784e-05  0.011269273  -0.009344834  -0.011114303  -0.006821409  -0.008882579  0.02613054  0.002686822  0.007152103  0.0014505194  0.025082488  0.0048149116  0.03901358  0.0124723585  -0.020381859  0.040694505  0.015819497  0.0038021083  0.0022370259  -0.009504782  -0.0216785  0.024278173  -0.014190648  -0.0069351993  -0.048500516  -0.03867663  -0.009317584  0.003057597  -0.0018372367  -0.023301752  0.013791516  0.0027729878  0.0176225  0.03693886  -0.013510072  0.009071173  0.00049645314  -0.003418785  0.012118234  -0.020652115  0.0054966896  -0.004234476  -0.0054757968  -0.011304651  -0.0042053885  -0.01686407  0.010638641  0.029134616  0.004605855  0.015352322  -0.053976934  -0.00069195364  -0.00041049914  -0.0025884472  -0.011133394  -0.028322827  0.007636209  0.014924187  -0.02370582  0.024208158  -0.011596176  -0.001974781  0.022528116  0.006313567  0.0008480534  -0.0067631765  -0.014609082  0.003342912  -0.004189058  -0.013472555  -0.0008561337  -0.039854236  0.0100562535  -0.0055548046  0.0009714934  -0.004876116  0.0058562616  0.0012724211  -0.022066532  -0.017511977  0.012242893  -0.0034564857  0.01510837  0.03818446  -0.007007603  -0.004648104  0.007266049  -0.007333046  0.00427279  0.0071816384  0.011337159  -0.0078833075  -0.024691595  -0.032412354  -0.024678905  0.016591491  0.011990175  0.009263229  -0.00788636  -0.009692491  0.0087565165  -0.031963807  -0.024587572  0.017643018  0.009314479  -0.0042965473  -0.040983025  -0.024228852  -0.0045290715  -0.0023521504  0.016522111  0.029721497  0.0029894104  0.003550388  -0.00091387273  0.013433603  0.010834962  -0.007321353  -0.020553507  0.00642232  -0.0105022155  -0.022669762  -0.011846142  -0.008734575  -0.008689047  -0.006260629  -0.00883065  0.0132174  0.009602971  0.000552294  0.044064384  -0.017195428  -0.015454753  -0.023975775  -0.005010274  0.010903892  0.0046280245  0.005225127  -0.00772726  0.033945236  0.0051409383  -0.0027090472  0.0122140655  -0.040769298  0.032261662  -0.012226992  0.0027103415  -0.0013121669  -0.008889093  -0.011541055  -0.007930268  0.014061067  -0.017838582  0.0059692776  -0.0036570171  -0.033309847  0.019653752  -0.02896453  0.014426461  -0.0013050953  0.0034084024  0.023614634  -0.025482506  -0.008690314  -0.009135913  0.0097655095  -0.023635278  -0.0074323537  -0.00183058  0.012739846  -0.0014941248  4.0243827e-05  0.032809235  0.012945054  0.0062357197  -0.022871334  -0.003492089  0.0031684733  -0.0041237567  -0.019210493  0.018507162  0.02845437  0.0067307907  0.012107828  0.0036838006  -0.009669841  -0.010543682  -0.016846832  -0.017488563  -0.008348334  -0.004769954  -0.003629106  0.0024699077  -0.017722167  -0.0016183592  0.01650819  0.0060185166  0.00765437  -0.011992874  -0.0009858476  0.022254037  0.0018766898  -0.009741939  0.006124051  -0.011086754  -0.009104326  0.004878374  -0.0004027958  -0.0022218681  -0.03719112  -0.0026858172  0.039952144  -0.011011535  0.024363196  0.025837779  0.0026692424  -0.02252926  0.001470903  -0.03468443  -0.019977048  -0.015759021  -0.00312915  -0.011983617  0.017330986  0.02659949  0.017946295  0.004097768  -0.00611666  0.010148005  0.021399954  0.0004484628  -0.011841756  0.01312611  0.0056209005  0.031644996  0.0071350895  0.024145102  -0.007071681  0.014492982  -0.008202819  -0.01682567  0.014778382  -0.011634513  -0.02849977  0.02843495  0.038383923  0.004526615  0.012855478  -0.0059463056  0.016186617  -0.003097561  0.007862841  0.0019961246  -0.008691482  -0.017756993  0.0014002398  0.0004693135  -0.010931792  0.020917015  0.016463475  0.014533344  0.022568002  -0.039472494  -0.010076576  0.0019646413  0.00075463345  0.00013270436  0.019082524  9.775213e-05  -0.01572091  0.024216503  0.011919239  -0.016217627  0.023820993  -0.016638031  0.014961429  -0.0077351164  0.0051586535  -0.014863963  0.021207519  0.0020074593  -0.022510773  -0.00052909716  0.010659689  -0.0073805973  -0.0026984878  0.003076064  -2.1404558e-05  0.0019775848  -0.025846701  0.003494129  -0.0011492637  0.0058847903  0.006591501  0.0005371784  0.024328586  -0.003199585  -0.017513676  0.0016985468  -0.00093848445  -0.015329561  0.009240686  0.015993552  -0.001990967  -0.0068404144  -0.04436622  0.026376445  -0.0070745554  -0.0009676792  0.004275812  0.022597296  0.0017831926  -0.004518067  0.008889689  -0.0046203323  0.015394496  0.004461033  -0.00361506  0.011413261  0.005099042  0.0037937113  0.032784052  0.004018488  0.005217348  0.00040448635  0.009829631  0.004195024  0.005586724  0.0050043697  -0.015056063  0.009844752  -0.0020710807  0.030245228  -0.007717473  0.010713488  0.0125400955  0.0024910374  -0.007240981  -0.005367076  0.003175632  -0.009321934  -0.012394471  -0.02188384  -0.0011158261  0.008766263  -0.010710598  -0.008855189  0.025684632  -0.10781639  0.008738417  0.035018582  -0.013618708  0.020938462  -0.004915906  0.024255779  0.049694907  -0.0009841014  0.012799365  -0.0008941669  0.016375504  -0.0038283728  0.019760882  -0.0014526399  0.014686012  0.026448578  -0.0046522757  0.010041946  -0.0053917663  0.0033199918  0.0012650097  0.01608673  0.0014766732  0.0027257546  0.014604493  -0.010120805  0.015664598  -0.0067400327  0.0114078475  -0.0010063926  0.0038473806  0.027355293  0.010056724  0.011476978  0.026406692  0.014011878  0.0111698955  0.012221931  0.007816563  0.011812571  0.0027232792  0.010757507  0.024837779  0.028440319  -0.011533953  0.015122419  0.009826583  -0.013627847  -0.0067926985  -0.022249065  0.0029863007  -0.014277253  0.018079914  0.017374907  0.0056563285  0.028657543  -0.008213734  -0.0011349644  0.014174425  -0.00036301452  -0.0072447695  -5.7324665e-05  0.033749428  0.024557764  -0.012830731  0.0077234292  -0.01697758  0.026638879  0.011842102  -0.031397507  0.0084705725  -0.011418776  0.0007090134  0.012013765  0.012309788  0.010426231  -0.009162159  -0.0013626321  0.025365032  -0.0026870805  0.025699692  -0.004451081  0.007173942  -0.009474167  0.0015710096  -0.033638846  0.01176229  -0.01978078  -0.012448914  -0.005608259  0.0065408275  0.0147388615  -0.010426333  0.021075604  -0.004792011  -0.0029100413  0.035955425  0.0023288825  0.032609247  0.015010998  0.008490528  -0.0146782715  -0.007195448  -0.107733116  0.0073907985  0.008723543  -0.008763947  0.023685107  -0.017531605  -0.02648396  -0.012355722  0.0023085244  -0.000109505876  -0.015417162  0.017039284  0.0051825596  0.025652256  -0.017363444  -0.023061335  -0.015021541  -0.012906098  -0.008115264  -0.027674977  0.012696998  -0.005832741  -0.014692408  0.0051914044  -0.010617868  -0.023343159  0.007863175  0.020208037  0.00667525  0.03225288  -0.015595535  0.031804763  -0.0015134453  -0.015679704  -0.00630948  -0.0013118291  0.02120476  0.0037473454  0.010378705  0.008089607  -0.000827994  -0.0021250416  -0.011045801  -0.013701678  0.00013143789  -0.018789819  -0.0059319194  0.018185105  0.03638528  -0.014260578  0.01252652  -0.014205052  -0.017253729  0.00044548934  0.045512423  0.0061149425  0.004790864  -0.010149556  0.00964471  -0.0066804676  -0.010460021  -0.034870796  0.0129496865  0.0109942295  -0.011986266  -0.022455405  -0.0047908723  0.0050150305  0.0067263953  0.009655893  0.030292735  -0.013834678  0.005693616  -0.011177993  0.02121076  0.025904644  -0.00048389324  -0.025104832  0.008159364  0.032195795  -0.015598805  0.0040145614  -0.0043710037  -0.00501561  -0.009139788  0.02450296  -0.016136212  -0.034721978  -0.008332984  -0.033978842  0.009600698  0.034978807  0.014597949  0.036018062  0.011822346  -0.005428906  0.015018359  0.017965317  -0.0075593595  0.02401178  0.007480138  0.002813029  -0.003780819  0.023571493  0.00012501137  0.016620332  0.012896408  -0.018477565  -0.004055197  0.019733464  0.008651585  0.016666604  -0.00090128474  0.013833137  -0.017742885  -0.0034887227  0.017057229  -0.009946509  -0.01161746  -0.009430897  0.015856741  -0.0029614451  -0.0065304856  -0.019181954  0.0056194384  0.02892564  0.018636312  0.03040619  0.010634649  -0.03370408  0.011670907  0.017650802  0.0027943114  -0.029566312  -0.014239476  0.003907507  -0.008466017  -0.0026815743  -0.004628056  0.012345233  0.020064415  -0.030875638  -0.011707571  -0.015906464  -0.0134538505  -0.004508817  0.001387505  0.017380109  0.01497375  -0.0028407273  0.010458699  -0.0010238034  0.001412179  -0.005028986  -0.014910037  0.03859345  0.010364576  -0.002814128  0.010538189  0.0073374268  0.025497753  0.005925297  -0.004650644  0.030742623  -0.005087261  0.0046096947  -0.01779908  0.0036711069  -0.020126786  0.023948004  0.0030218454  0.003206163  0.008356931  0.038239356  -0.012506623  0.004209553  0.0002848955  0.0022854917  0.019761607  -0.007945318  0.019924002  -0.013335747  -0.0138382595  0.0034136595  -5.279207e-05  -0.0019577479  -0.010512147  0.010117825  -0.010633305  -0.030290164  0.028704256  0.004580871  0.008945956  0.011915334  0.013987616  -0.023296442  -0.0050126067  0.00400375  0.017624462  -0.018467162  0.014564563  0.0100138225  0.012838216  -0.013637003  -0.008463769  -0.008993436  0.0009538622  0.0017084406  0.03793503  0.0061268797  -0.0063328943  0.042410944  -0.0014506298  -0.0019639255  -0.008504703  -0.005957067  -0.002868365  -0.027344849  0.03657695  -0.016425481  0.01590535  -0.029589884  -0.010292017  -0.0010045744  -0.0003172476  0.031363286  0.011518851  0.0037958554  -0.023442952  -0.018105017  -0.011709781  0.0011195645  -0.01109574  0.024353888  -0.010054419  -0.010362116  -0.009833633  0.004308146  -0.041414946  0.009451233  0.022686578  -0.0040781423  -0.00077331526  0.039197262  0.025796488  0.012711834  -0.028409922  -0.006928921  -0.027514502  -0.046315134  -0.011104355  0.0005174827  0.0077030226  0.005774164  0.0044978852  0.040783178  0.017166024  0.0071020448  0.0076008486  0.010377658  -0.0087480815  0.008401779  0.007457895  0.05030226  0.03242825  0.021958603  0.0077262255  -0.023754803  -0.014910528  0.008066041  0.030343337  -0.023356864  -0.014817291  -0.004801622  -0.02180537  0.009085949  -0.012801381  0.026126107  0.019482637  -7.567944e-05  0.033780787  0.023381634  0.0023453608  -0.034647577  -0.008861307  -0.00784471  0.014069191  -0.0023100302  -0.013938628  0.03623015  0.001194918  -0.0036143926  -0.02387858  -0.014665474  -0.01147029  0.010962145  0.01552968  -0.0067579136  -0.026584942  0.0017787276  -0.011476607  -0.024783341  0.008846277  0.01928974  0.018863583  0.009301973  0.012805886  0.00754355  0.006933095  0.024751842  0.007356492  -0.0053945105  0.018698823  0.0076809307  0.00022862617  0.007247671  -0.0050033224  0.0035732079  -0.023105638  0.0044933497  -0.01747071  0.019494532  0.017995965  0.009168988  -0.016917467  -0.006255659  0.010988794  -0.018871805  0.0008474927  0.0059864945  -0.026661547  -0.0021551421  0.0018692138  -0.012097446  0.017966114  -0.0065010083  0.019984879  -0.0041827797  0.011977895  -0.017591119  -0.00877424  0.0022706154  -0.00109199  0.0064556124  0.0011669006  -0.013969493  0.016362425  0.002382007  0.0005582402  0.025710223  0.0020601987  -0.0020379033  0.0004059675  0.007298375  -0.016413435  0.006846794  -0.019234598  0.003191488  0.02621221  0.0041264463  0.009884593  -0.0024908655  -0.014837363  0.013018951  -0.018217288  -0.015695574  -0.033560317  -0.021458955  -0.0043239286  -0.013288222  0.024304468  -0.015452354  -0.0073697236  -0.010630798  0.013904946  -0.0128583405  0.023849335  0.010290855  0.016011238  0.009635872  -0.023516444  0.023394218  0.005073917  0.0036661183  -0.018062387  0.009160961  -0.0039196364  -0.017067412  0.015430958  0.017886877  0.012357711  -0.018812211  -0.010178542  -0.0007032907  -0.023975024  -0.008377944  0.013577126  -0.004089572  -0.010856036  -0.0016711465  0.008612353  -0.0007418875  -0.0028398342  0.005481603  0.022832958  -0.008289871  0.018385645  -0.017175106  0.008464917  0.019623378  0.012014454  0.0002060691  0.03318942  0.0078358175  0.0008580571  -0.0062582074  0.025655175  0.008162164  0.019639209  -0.0022434904  -0.01237055  -0.03127353  0.01801663  0.009538972  0.033582523  0.004016233  0.004925219  -0.017257577  0.0035777881  0.0025937427  0.0023950448  0.027682792  0.010467164  -0.0075505907  0.0028132088  -0.034104563  0.02273432  0.018907504  0.010958747  -0.00074817054  0.0045482777  -0.007015562  0.027993644  0.009232979  -0.010193017  0.017078696  -0.027208135  -0.0052318717  -0.0038235995  0.0067481045  -0.022159906  0.01910075  -0.0037396431  -0.012245302  0.02063116  0.06085054  -0.016323732  -0.013176331  0.021327646  0.003985784  0.016510062  0.028571533  -0.008585194  0.0035246075  0.004310466  0.009002242  0.034481917  -0.0033398056  -0.005797421  -0.004184489  0.02250656  -0.003349625  -0.010050924  0.01691792  -0.017219927  -0.019775812  -0.011822326  0.01948461  0.022309931  0.013855338  0.0025262686  0.0031362036  0.020285733  -0.011252794  -0.01096324  -0.0038910892  0.018855931  0.009831686  -0.009718961  -0.01704419  0.013964589  0.01592629  0.00017856833  0.008041894  -0.048620895  -0.016944937  0.010528014  -0.008770933  0.047058173  -0.012183363  0.0048390524  0.016517675  -0.017146332  -0.0054122494  0.0036161789  0.032662287  0.015685312  0.014788695  -0.0035024984  0.0023314657  -0.013930395  0.0029067046  0.022976948  0.0074455873  -0.0099661285  -0.0074975323  -0.0047537293  -0.0044206716  0.00086517277  -0.0008000461  0.00405272  -0.00093335693  -0.009119913  0.00910346  0.0021675874  0.0044345353  -0.018319186  0.0028036132  -0.038241256  -0.0053569097  0.0062161805  -0.0022881748  -0.009850819  -0.012680204  0.004744669  0.019757805  -0.035153177  -0.007023141  -0.020504141  -0.0023127785  -0.0018710126  -0.00031408336  -0.0017733377  -0.00012352393  0.008628578  0.008028983  -0.014330687  0.023462012  0.013759065  -0.019746646  -0.015217788  0.0012786827  0.012386497  0.019252686  0.0071565816  -0.027290555  -0.004891179  -0.016028617  0.0030367572  -0.0051389667  0.0012906848  0.008026189  0.0036809838  0.0015108085  0.030869115  0.006411283  0.0070543326  -0.010869024  0.029752495  -0.014288736  -0.0127695855  0.0005792105  0.019056085  -0.0031987298  0.011247617  -0.012821868  0.02212587  0.002542155  0.0032015631  -0.022535196  0.024987955  -0.021754516  0.006257285  -0.022485917  0.0019852368  0.013887089  -0.024380008  0.006579584  0.10884627  -0.005852202  0.0036304167  0.009669266  0.0018401373  0.0039270325  0.006519534  0.00019330555  0.0007044353  -0.025862018  0.002745832  -0.011556123  -0.002407414  -0.01754068  0.026837936  0.020349186  0.0026906661  -0.0060321596  0.006585288  0.004461078  0.04110151  -0.020336319  0.0020029843  0.065213546  0.00957922  -0.0036745511  -0.0026947616  -0.0070598437  0.007221392  -0.008635502  0.0052836244  -0.009013815  -0.012528702  0.008339578  -0.007407219  -0.014481742  0.02704245  0.023389414  -0.011603324  -0.0646552  0.012322428  -0.008842523  -0.0033768956  -0.015438089  -0.019333974  0.012898529  0.005959619  -0.026787993  -0.014279389  0.016576305  0.031439036  0.013109399  0.013034055  -0.011485707  0.02860338  -0.009747954  -0.0003408141  -0.025041873  0.021157436  -0.01047002  0.007118851  0.00534564  -0.008388199  -0.0026721645  0.015271841  0.025498621  -0.02918085  -0.012049213  0.010991697  -0.011855756  -0.0046683294  -0.012917182  0.015275982  -0.005802347  0.0014832588  0.0036412622  -0.019049197  -0.014865329  -0.01769985  -0.030344546  8.5586915e-05  0.007910005  0.0069328565  -0.005419983  0.0068219816  0.026866136  0.022606928  -0.010385279  0.01151633  -0.03529577  0.007300774  0.00090146787  -0.00066220626  0.02683109  -0.019294316  -0.015199653  0.0066671795  0.021901801  0.0007320921  0.0021871438  -0.030925155  -0.007411245  -0.0109902695  -0.022912538  -0.0018919334  0.0030571176  0.0010618345  -0.013994131  0.019418838  0.04619265  0.00811334  0.006514549  0.025483042  0.012268835  0.04396401  0.011844159  -0.011355526  -0.021673126  0.01076465  -0.007309776  -0.017631257  -0.0049989  0.009338083  0.027316531  -0.00053161115  0.01203775  -0.031875946  -1.530507e-05  0.001687341  0.013552548  0.023394097  -0.012464411  -0.010211409  -0.0047764666  -0.023271268  -0.006576961  0.00093232  -0.0017719037  0.0053569544  0.0004469953  -0.0077863215  0.020327445  -0.032698702  -0.00023065293  -0.022765804  0.0018081162  0.016932717  -0.025741948  -0.011055257  -0.00061117066  -0.022042338  0.024015438  0.00033689174  0.011195226  -0.02825477  -0.019092405  -0.026742928  -0.009307035  -0.002697339  -0.008720815  -0.02157867  -0.009031601  0.006826353  -0.0032259054  0.019158527  0.0023253213  0.010419767  0.01594489  0.01081851  -0.0340351  -0.014153917  0.011526417  0.011099938  0.0029862637  -0.008431487  -0.004459396  0.023523564  0.018137008  -0.009819573  0.002990396  -0.020460818  0.016425634  -0.006305394  0.00241062  0.009707123  0.003973726  -0.023009626  0.008357648  -0.015572387  0.021820562  -0.01329877  0.021789104  -0.0060666716  0.024842815  0.00137677  0.005571901  -0.012941861  0.009614074  -0.0024738878  -0.00829789  0.0009034222  0.01115179  -0.004983079  0.006467162  0.039360657  0.009606845  0.02168264  0.0055739237  0.017175896  -0.007009325  -0.038031213  -0.0007766522  -0.01190319  0.028251173  -0.011478961  0.010397322  -0.046908993  0.017704763  -0.00312331  0.0069807568  0.027745692  -0.0636457  -0.024195727  -0.017701134  -0.021216808  0.012083153  0.0019262092  0.02037561  -0.00041202383  0.01510783  -0.0021407441  -0.009531918  -0.019117912  -0.0034893488  -0.012592162  -0.003971604  -8.40629e-05  -0.028100394  0.009934991  -0.009872078  0.009621531  -0.00053471606  -0.01740316  -0.004477322  -0.02195216  -0.011759694  -0.020708289  0.0006323299  0.012100056  -0.012808224  -0.010073628  -0.0037747067  -0.006291197  -0.0007904516  0.0093449615  -0.0042960597  0.03542139  0.018281816  -0.0048388285  -0.001731073  -0.0023932396  0.02072431  0.0226048  0.028916612  0.011944625  0.0044428175  -0.008003873  0.0038513953  0.0056068585  -0.0042376406  -0.010028582  0.021661974  0.028134203  -0.030314738  -0.0025416454  0.0049285158  0.0065304637  -0.0036014535  0.0028730184  -0.003857652  0.01671199  -0.041190866  0.0091459025  -0.005361912  -0.013276623  -0.017199248  0.008260244  0.029801136  -0.015891425  -0.024076052  0.011065235  0.008434631  0.013091206  -0.0038126193  0.019122664  0.0059029027  0.08260534  -0.028245213  -0.002694322  0.013015504  -0.009761158  -0.008572939  -0.0025125928  -0.0023616417  -0.01017084  -0.023086756  -0.007912171  -0.011425106  -0.010386662  0.011898804  -0.02262358  -0.005691258  0.0062100575  -0.01097928  0.0016503705  -0.0051526665  0.019089295  0.00064628624  0.006510204  -0.0075956434  0.013232029  0.0013703037  0.012521445  -0.026653975  0.0049316576  0.012276566  0.007445809  -0.006621571  -0.0114158625  0.009332936  -0.0011923712  0.03294739  -0.010477419  -0.00055138016  -0.0017931114  -0.0113498615  -0.024081895  0.043609865  -0.008292186  0.007123727  0.012236671  0.0037139745  -0.00593123  -0.019509602  0.021947557  -0.008636201  -0.008730013  0.025109356  0.013910047  0.014277044  0.016256709  -0.020833392  0.020339001  0.02752797  -0.0059031756  -0.0042291204  0.027346207  -7.543562e-05  0.011081706  0.013140049  0.018869521  -0.009346744  -0.055545192  -0.0007524457  -0.033724263  0.02044709  -0.00015162637  -0.06469503  -0.0072248527  -0.026248828  -0.009613887  -0.0018478344  -0.02287167  0.001887103  -0.025151808  -0.022163182  -0.011553012  0.002604313  -0.008657735  -0.017948609  0.0053443313  -0.012558397  -0.0119429985  -0.027336922  0.004957137  -0.022146668  0.013164042  0.019950874  -0.02168118  0.013345674  0.0016268762  -0.012954933  -0.00045600845  0.0046150126  0.01951492  -0.007335013  -0.0071061654  0.0016405203  -0.0062886374  0.005387927  0.0056030196  -0.031164454  0.01416536  0.006807883  0.0014431761  0.010599206  0.020391518  0.0111671155  -0.013987454  0.011104833  -0.010483207  0.006381567  -0.029777965  0.010330101  -0.01399177  -0.028042957  0.02045341  0.006745381  0.01157081  -0.0058276416  -0.014335892  0.010656788  -0.0111445505  -0.009101607  0.0048749642  -0.021238573  -0.012275333  -0.012343868  0.0012839127  -0.0049449815  0.0055109174  -0.013314927  0.011462324  0.0013035123  -0.014557069  -0.003779373  -0.007174992  0.010021336  -0.0018448946  0.010776298  -0.004759061  -0.02578395  0.008882314  0.014653177  -0.022252524  0.0023567374  -0.008516248  -0.03596584  0.0049006157  0.013092103  0.015737135  0.008547605  -0.00278747  0.01895942  0.016991941  -0.0113635855  0.014003663  0.016481303  0.013005349  0.007270305  -0.006296138  -0.0235628  0.003456933  0.015740272  -0.014442633  -0.02063385  -0.022614958  0.010137031  0.0015423927  -0.024115961  -0.03632687  0.00026300986  -0.00069556804  -0.0054321345  -0.0089995535  -0.00035099557  0.028561383  -0.014078761  -0.031037027  0.013911903  -0.009680944  0.003266066  0.008689918  -0.015169558  -0.002212063]',\n",
       " str)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"embeddings\"].iloc[0],type(df[\"embeddings\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the saved embeddings into manageable arrays\n",
    "df[\"embeddings_array\"]=df[\"embeddings\"].apply(lambda x : np.fromstring(x.strip('[]'), sep=' '))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>embeddings</th>\n",
       "      <th>Alert User</th>\n",
       "      <th>Ambient Atmosphere</th>\n",
       "      <th>Ambient Luminance</th>\n",
       "      <th>Ambient Temperature</th>\n",
       "      <th>Control Hub</th>\n",
       "      <th>Energy Saving</th>\n",
       "      <th>Gardening</th>\n",
       "      <th>Other</th>\n",
       "      <th>Other Appliances</th>\n",
       "      <th>Outlet Control</th>\n",
       "      <th>Robot Control</th>\n",
       "      <th>Security</th>\n",
       "      <th>embeddings_array</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[5.8760797e-06  0.018332329  0.032247532  -0.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[5.8760797e-06, 0.018332329, 0.032247532, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.01548752  0.007120902  0.032546464  -0.005...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.01548752, 0.007120902, 0.032546464, -0.005...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.007748441  0.0021770685  0.036084786  -0.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.007748441, 0.0021770685, 0.036084786, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.0013106825  0.00499818  0.053116668  -0.00...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.0013106825, 0.00499818, 0.053116668, -0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.013440807  -0.019121878  0.019484065  -0.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.013440807, -0.019121878, 0.019484065, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>[0.0040453877  0.028940763  0.03343941  0.0087...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.0040453877, 0.028940763, 0.03343941, 0.0087...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>[-0.015449206  0.001333692  0.006457404  -0.02...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.015449206, 0.001333692, 0.006457404, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>[-0.01638672  -0.0019023608  0.05313262  -0.01...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.01638672, -0.0019023608, 0.05313262, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>[-0.018889135  0.01379838  0.0349957  0.007016...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.018889135, 0.01379838, 0.0349957, 0.007016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>[-0.016756753  -0.023842216  0.05784838  -0.00...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.016756753, -0.023842216, 0.05784838, -0.00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2560 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             embeddings  Alert User  \\\n",
       "0     [5.8760797e-06  0.018332329  0.032247532  -0.0...           0   \n",
       "1     [-0.01548752  0.007120902  0.032546464  -0.005...           0   \n",
       "2     [-0.007748441  0.0021770685  0.036084786  -0.0...           0   \n",
       "3     [-0.0013106825  0.00499818  0.053116668  -0.00...           0   \n",
       "4     [-0.013440807  -0.019121878  0.019484065  -0.0...           1   \n",
       "...                                                 ...         ...   \n",
       "2555  [0.0040453877  0.028940763  0.03343941  0.0087...           0   \n",
       "2556  [-0.015449206  0.001333692  0.006457404  -0.02...           1   \n",
       "2557  [-0.01638672  -0.0019023608  0.05313262  -0.01...           0   \n",
       "2558  [-0.018889135  0.01379838  0.0349957  0.007016...           0   \n",
       "2559  [-0.016756753  -0.023842216  0.05784838  -0.00...           0   \n",
       "\n",
       "      Ambient Atmosphere  Ambient Luminance  Ambient Temperature  Control Hub  \\\n",
       "0                      0                  1                    0            0   \n",
       "1                      0                  1                    0            0   \n",
       "2                      0                  1                    0            0   \n",
       "3                      0                  0                    0            1   \n",
       "4                      0                  0                    0            0   \n",
       "...                  ...                ...                  ...          ...   \n",
       "2555                   0                  1                    0            0   \n",
       "2556                   0                  0                    0            0   \n",
       "2557                   0                  0                    0            0   \n",
       "2558                   1                  0                    0            0   \n",
       "2559                   0                  0                    0            0   \n",
       "\n",
       "      Energy Saving  Gardening  Other  Other Appliances  Outlet Control  \\\n",
       "0                 0          0      0                 0               0   \n",
       "1                 0          0      0                 0               0   \n",
       "2                 0          0      0                 0               0   \n",
       "3                 0          0      0                 0               0   \n",
       "4                 0          0      0                 0               0   \n",
       "...             ...        ...    ...               ...             ...   \n",
       "2555              0          0      0                 0               0   \n",
       "2556              0          0      0                 0               0   \n",
       "2557              0          0      1                 0               0   \n",
       "2558              0          0      0                 0               0   \n",
       "2559              0          0      1                 0               0   \n",
       "\n",
       "      Robot Control  Security  \\\n",
       "0                 0         0   \n",
       "1                 0         0   \n",
       "2                 0         0   \n",
       "3                 0         0   \n",
       "4                 0         0   \n",
       "...             ...       ...   \n",
       "2555              0         0   \n",
       "2556              0         0   \n",
       "2557              0         0   \n",
       "2558              0         0   \n",
       "2559              0         0   \n",
       "\n",
       "                                       embeddings_array  \n",
       "0     [5.8760797e-06, 0.018332329, 0.032247532, -0.0...  \n",
       "1     [-0.01548752, 0.007120902, 0.032546464, -0.005...  \n",
       "2     [-0.007748441, 0.0021770685, 0.036084786, -0.0...  \n",
       "3     [-0.0013106825, 0.00499818, 0.053116668, -0.00...  \n",
       "4     [-0.013440807, -0.019121878, 0.019484065, -0.0...  \n",
       "...                                                 ...  \n",
       "2555  [0.0040453877, 0.028940763, 0.03343941, 0.0087...  \n",
       "2556  [-0.015449206, 0.001333692, 0.006457404, -0.02...  \n",
       "2557  [-0.01638672, -0.0019023608, 0.05313262, -0.01...  \n",
       "2558  [-0.018889135, 0.01379838, 0.0349957, 0.007016...  \n",
       "2559  [-0.016756753, -0.023842216, 0.05784838, -0.00...  \n",
       "\n",
       "[2560 rows x 14 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 5.8760797e-06,  1.8332329e-02,  3.2247532e-02, ...,\n",
       "         8.6899180e-03, -1.5169558e-02, -2.2120630e-03]),\n",
       " numpy.ndarray)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"embeddings_array\"].iloc[0],type(df[\"embeddings_array\"].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create X, y for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(list(df[\"embeddings_array\"]))\n",
    "y= df[labels].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 5.8760797e-06,  1.8332329e-02,  3.2247532e-02, ...,\n",
       "          8.6899180e-03, -1.5169558e-02, -2.2120630e-03],\n",
       "        [-1.5487520e-02,  7.1209020e-03,  3.2546464e-02, ...,\n",
       "         -2.2918832e-02, -4.1488796e-03,  2.4867827e-02],\n",
       "        [-7.7484410e-03,  2.1770685e-03,  3.6084786e-02, ...,\n",
       "         -1.1790700e-02, -6.7398650e-03,  1.2477863e-02],\n",
       "        ...,\n",
       "        [-1.6386720e-02, -1.9023608e-03,  5.3132620e-02, ...,\n",
       "         -2.0504981e-02, -3.2578380e-02, -3.3031139e-03],\n",
       "        [-1.8889135e-02,  1.3798380e-02,  3.4995700e-02, ...,\n",
       "          4.3293600e-03, -1.0879731e-02,  5.3803160e-03],\n",
       "        [-1.6756753e-02, -2.3842216e-02,  5.7848380e-02, ...,\n",
       "          1.2718450e-03, -1.1283917e-02,  2.0400228e-02]]),\n",
       " array([[0, 0, 1, ..., 0, 0, 0],\n",
       "        [0, 0, 1, ..., 0, 0, 0],\n",
       "        [0, 0, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 1, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets with stratified sampling. Validation set not taken into consideration at the moment.\n",
    "# A cross validation methods can be also applied.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Random Forest model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 97.60%\n",
      "Test Accuracy: 12.50%\n",
      "Train F1-micro: 0.99\n",
      "Test F1-micro: 0.23\n",
      "Train F1-macro: 0.98\n",
      "Test F1-macro: 0.17\n",
      "Train F1-weighted: 0.99\n",
      "Test F1-weighted: 0.22\n"
     ]
    }
   ],
   "source": [
    "# Initialize RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=30, random_state=42)\n",
    "\n",
    "# Use MultiOutputClassifier to handle multi-label classification\n",
    "multi_rf = MultiOutputClassifier(rf, n_jobs=-1)\n",
    "\n",
    "# Train the model\n",
    "multi_rf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = multi_rf.predict(X_train)\n",
    "y_pred = multi_rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "train_f1_micro=f1_score(y_train, y_pred_train,average='micro')\n",
    "test_f1_micro=f1_score(y_test, y_pred,average='micro')\n",
    "\n",
    "train_f1_macro=f1_score(y_train, y_pred_train,average='macro')\n",
    "test_f1_macro=f1_score(y_test, y_pred,average='macro')\n",
    "\n",
    "train_f1_weighted=f1_score(y_train, y_pred_train,average='weighted')# weighted take into account class unbalance\n",
    "test_f1_weighted=f1_score(y_test, y_pred,average='weighted')\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "print(f\"Train F1-micro: {train_f1_micro:.2f}\")\n",
    "print(f\"Test F1-micro: {test_f1_micro :.2f}\")\n",
    "\n",
    "print(f\"Train F1-macro: {train_f1_macro:.2f}\")\n",
    "print(f\"Test F1-macro: {test_f1_macro :.2f}\")\n",
    "\n",
    "print(f\"Train F1-weighted: {train_f1_weighted:.2f}\")\n",
    "print(f\"Test F1-weighted: {test_f1_weighted :.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The results show that the model is in overfittings (big gap between train and test performances)\n",
    "The model is too complex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       187\n",
      "           1       0.99      0.98      0.98       161\n",
      "           2       1.00      0.99      0.99       430\n",
      "           3       1.00      0.99      1.00       245\n",
      "           4       1.00      0.93      0.96       139\n",
      "           5       1.00      0.88      0.93        24\n",
      "           6       1.00      0.95      0.97        19\n",
      "           7       1.00      0.98      0.99       247\n",
      "           8       1.00      0.97      0.99        71\n",
      "           9       1.00      0.83      0.91        29\n",
      "          10       1.00      0.98      0.99        65\n",
      "          11       1.00      1.00      1.00       243\n",
      "\n",
      "   micro avg       1.00      0.98      0.99      1860\n",
      "   macro avg       1.00      0.95      0.98      1860\n",
      "weighted avg       1.00      0.98      0.99      1860\n",
      " samples avg       0.98      0.98      0.98      1860\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicleonard\\AppData\\Local\\anaconda3\\envs\\hiis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.01      0.02        80\n",
      "           1       0.67      0.06      0.11        70\n",
      "           2       0.81      0.26      0.39       184\n",
      "           3       0.93      0.13      0.23       106\n",
      "           4       1.00      0.05      0.10        60\n",
      "           5       1.00      0.09      0.17        11\n",
      "           6       0.00      0.00      0.00         8\n",
      "           7       0.78      0.17      0.28       105\n",
      "           8       1.00      0.07      0.12        30\n",
      "           9       0.00      0.00      0.00        13\n",
      "          10       1.00      0.25      0.40        28\n",
      "          11       0.83      0.10      0.17       104\n",
      "\n",
      "   micro avg       0.84      0.13      0.23       799\n",
      "   macro avg       0.75      0.10      0.17       799\n",
      "weighted avg       0.84      0.13      0.22       799\n",
      " samples avg       0.14      0.13      0.13       799\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicleonard\\AppData\\Local\\anaconda3\\envs\\hiis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nicleonard\\AppData\\Local\\anaconda3\\envs\\hiis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 18.53%\n",
      "Test Accuracy: 14.71%\n",
      "Train F1-micro: 0.31\n",
      "Test F1-micro: 0.25\n",
      "Train F1-macro: 0.18\n",
      "Test F1-macro: 0.13\n",
      "Train F1-weighted: 0.30\n",
      "Test F1-weighted: 0.23\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Initialize LogisticRegression\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "# Use MultiOutputClassifier to handle multi-label classification\n",
    "multi_logreg = MultiOutputClassifier(logreg, n_jobs=-1)\n",
    "\n",
    "# Train the model\n",
    "multi_logreg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_train = multi_logreg.predict(X_train)\n",
    "y_pred = multi_logreg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "train_f1_micro=f1_score(y_train, y_pred_train,average='micro')\n",
    "test_f1_micro=f1_score(y_test, y_pred,average='micro')\n",
    "\n",
    "train_f1_macro=f1_score(y_train, y_pred_train,average='macro')\n",
    "test_f1_macro=f1_score(y_test, y_pred,average='macro')\n",
    "\n",
    "train_f1_weighted=f1_score(y_train, y_pred_train,average='weighted')# weighted take into account class unbalance\n",
    "test_f1_weighted=f1_score(y_test, y_pred,average='weighted')\n",
    "\n",
    "print(f\"Train Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "\n",
    "print(f\"Train F1-micro: {train_f1_micro:.2f}\")\n",
    "print(f\"Test F1-micro: {test_f1_micro :.2f}\")\n",
    "\n",
    "print(f\"Train F1-macro: {train_f1_macro:.2f}\")\n",
    "print(f\"Test F1-macro: {test_f1_macro :.2f}\")\n",
    "\n",
    "print(f\"Train F1-weighted: {train_f1_weighted:.2f}\")\n",
    "print(f\"Test F1-weighted: {test_f1_weighted :.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.16      0.28       187\n",
      "           1       1.00      0.10      0.18       161\n",
      "           2       0.90      0.33      0.48       430\n",
      "           3       0.96      0.31      0.47       245\n",
      "           4       0.00      0.00      0.00       139\n",
      "           5       0.00      0.00      0.00        24\n",
      "           6       0.00      0.00      0.00        19\n",
      "           7       1.00      0.16      0.28       247\n",
      "           8       0.00      0.00      0.00        71\n",
      "           9       0.00      0.00      0.00        29\n",
      "          10       1.00      0.09      0.17        65\n",
      "          11       0.98      0.17      0.29       243\n",
      "\n",
      "   micro avg       0.94      0.19      0.31      1860\n",
      "   macro avg       0.57      0.11      0.18      1860\n",
      "weighted avg       0.81      0.19      0.30      1860\n",
      " samples avg       0.19      0.19      0.19      1860\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicleonard\\AppData\\Local\\anaconda3\\envs\\hiis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nicleonard\\AppData\\Local\\anaconda3\\envs\\hiis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.05      0.10        80\n",
      "           1       0.67      0.03      0.05        70\n",
      "           2       0.80      0.32      0.46       184\n",
      "           3       0.94      0.16      0.27       106\n",
      "           4       0.00      0.00      0.00        60\n",
      "           5       0.00      0.00      0.00        11\n",
      "           6       0.00      0.00      0.00         8\n",
      "           7       1.00      0.11      0.21       105\n",
      "           8       0.00      0.00      0.00        30\n",
      "           9       0.00      0.00      0.00        13\n",
      "          10       1.00      0.11      0.19        28\n",
      "          11       0.91      0.19      0.32       104\n",
      "\n",
      "   micro avg       0.86      0.15      0.25       799\n",
      "   macro avg       0.53      0.08      0.13       799\n",
      "weighted avg       0.75      0.15      0.23       799\n",
      " samples avg       0.15      0.15      0.15       799\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicleonard\\AppData\\Local\\anaconda3\\envs\\hiis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\nicleonard\\AppData\\Local\\anaconda3\\envs\\hiis\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print (classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The results show less better test performance, less overfitting.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
